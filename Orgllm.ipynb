{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4c6cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adarsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- LangChain Imports ---\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_core.messages import SystemMessage, HumanMessage # For clarity if you use chat history\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "#from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6eee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"GEMINI_API_KEY\") or os.environ.get(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API Key not found. Please set GEMINI_API_KEY or GOOGLE_API_KEY.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12559664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! I can certainly help you with that.\n",
      "\n",
      "Here's the information you're looking for:\n",
      "\n",
      "### Average Height of a Lion\n",
      "\n",
      "Lions are measured by their **shoulder height** (the distance from the ground to the top of their shoulder when standing on all fours).\n",
      "\n",
      "*   **Male Lions:** Typically stand between **1.0 to 1.2 meters (3.3 to 3.9 feet)** at the shoulder.\n",
      "*   **Female Lions:** Are slightly smaller, usually between **0.9 to 1.1 meters (3.0 to 3.6 feet)** at the shoulder.\n",
      "\n",
      "### Whale Weight\n",
      "\n",
      "It's impossible to give an \"average\" weight for a whale because there's an enormous size difference between the various species of whales. They range from relatively small to the largest animal on Earth!\n",
      "\n",
      "Here are some examples to give you an idea of the range:\n",
      "\n",
      "*   **Blue Whale (the largest animal on Earth):** Can weigh anywhere from **100 to 200 metric tons (220,000 to 440,000 pounds)**, with some individuals exceeding this.\n",
      "*   **Humpback Whale:** Typically weighs between **25 to 40 metric tons (55,000 to 88,000 pounds)**.\n",
      "*   **Gray Whale:** Usually weighs around **15 to 40 metric tons (33,000 to 88,000 pounds)**.\n",
      "*   **Dwarf Sperm Whale (one of the smaller \"true\" whales):** Weighs around **136 to 272 kg (300 to 600 pounds)**.\n",
      "\n",
      "So, as you can see, a whale's weight depends entirely on its species!\n"
     ]
    }
   ],
   "source": [
    "LLM = ChatGoogleGenerativeAI(\n",
    "    model= \"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    #allow_dangerous_code=True,\n",
    "    google_api_key=api_key\n",
    "\n",
    ")\n",
    "\n",
    "analysis_prompt = \"\"\"Hello there i what is the average height of a lion and also whale weight.\n",
    "\"\"\"\n",
    "\n",
    "ai_mmsg = LLM.invoke(analysis_prompt)\n",
    "print(ai_mmsg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abbf24",
   "metadata": {},
   "source": [
    "### Trying to upload csv or excel file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7abb35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "csvloader = CSVLoader(file_path=r\"C:\\Users\\adarsh\\OneDrive\\Documents\\My Coding Project\\Assist\\train.csv\")\n",
    "#excel_loader = UnstructuredExcelLoader(file_path=\"\",mode=\"elements\")\n",
    "\n",
    "csv_doc = csvloader.load()\n",
    "#excel_doc = excel_loader()\n",
    "\n",
    "\n",
    "print(len(csv_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881202f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai_litellm.litellm import LiteLLM\n",
    "import pandasai as pai \n",
    "import pandas as pd\n",
    "from litellm import token_counter\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyB0pmTvTBZ_HHVmG9ujEB9PthfVWeulwX4\"\n",
    "\n",
    "# --- Data Setup ---\n",
    "df = pai.read_csv(\"train.csv\")\n",
    "\n",
    "# --- LLM and SmartDataframe Setup ---\n",
    "# 1. Initialize the LiteLLM client, which uses the key set above\n",
    "llm = LiteLLM(model=\"gemini/gemini-2.5-flash\")\n",
    "\n",
    "# 2. Create the SmartDataframe\n",
    "smart_df = SmartDataframe(\n",
    "    df, \n",
    "    config={\"llm\": llm, \"verbose\": True,\"enable_cache\":True} \n",
    ")\n",
    "\n",
    "# --- Run the Query ---\n",
    "prompt = \"creat a subplot which tells about data like a dashboard.\"\n",
    "response = smart_df.chat(prompt)\n",
    "\n",
    "print(\"\\n--- Generated Result ---\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pdf = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#print(pdf['Sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfaf1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run(\"print(1+1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867250ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 53)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    ")\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load API Key\n",
    "# -------------------------------------------\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Missing Gemini API key\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Tool Schemas (No warnings!)\n",
    "# -------------------------------------------\n",
    "class CSVInput(BaseModel):\n",
    "    file_path: str = Field(description=\"Path to a CSV file\")\n",
    "\n",
    "\n",
    "class PlotInput(BaseModel):\n",
    "    data_json: str = Field(description=\"DataFrame JSON in orient='split'\")\n",
    "    x: str = Field(description=\"X-axis column\")\n",
    "    y: str = Field(description=\"Y-axis column\")\n",
    "    plot_type: str = Field(default=\"bar\", description=\"bar or line\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Tools (Clean & Gemini-safe)\n",
    "# -------------------------------------------\n",
    "@tool(args_schema=CSVInput)\n",
    "def csv_loader(input: CSVInput):\n",
    "    \"\"\"Load CSV and return JSON (orient='split').\"\"\"\n",
    "    df = pd.read_csv(input.file_path)\n",
    "    return df.to_json(orient='split')\n",
    "\n",
    "\n",
    "@tool(args_schema=PlotInput)\n",
    "def plotter(input: PlotInput):\n",
    "    \"\"\"Plot a DataFrame and save as plot.png.\"\"\"\n",
    "    df = pd.read_json(input.data_json, orient='split')\n",
    "\n",
    "    df.plot(kind=input.plot_type, x=input.x, y=input.y)\n",
    "    plt.savefig(\"plot.png\")\n",
    "\n",
    "    return \"Plot saved as plot.png\"\n",
    "\n",
    "\n",
    "python_tool = PythonREPLTool( python_opts={\"packages\": [\"pandas\",\"numpy\", \"matplotlib\", \"seaborn\", \"plotly\", \"statsmodels\"]}\n",
    "                             )\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# LLM setup\n",
    "# -------------------------------------------\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0,\n",
    "    allow_dangerous_code=True,\n",
    ")\n",
    "\n",
    "tools = [csv_loader, plotter, python_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Conversation setup\n",
    "# -------------------------------------------\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful data analysis assistant.\"),\n",
    "    HumanMessage(content=\"\"\"\n",
    "Load train.csv, calculate average of the age, plot it, and summarize results.\n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "# -------------------------------------------\n",
    "# Tool Execution Loop (Corrected)\n",
    "# -------------------------------------------\n",
    "for _ in range(10):\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    tool_calls = response.additional_kwargs.get(\"tool_calls\", [])\n",
    "\n",
    "    # If model is done â†’ final answer\n",
    "    if not tool_calls:\n",
    "        if response.content.strip():\n",
    "            print(\"\\nFINAL ANSWER:\\n\", response.content)\n",
    "        else:\n",
    "            # force summary\n",
    "            summary = llm.invoke(messages + [\n",
    "                HumanMessage(content=\"Summarize the results.\")\n",
    "            ])\n",
    "            print(\"\\nFINAL ANSWER:\\n\", summary.content)\n",
    "        break\n",
    "\n",
    "    # Handle each tool call\n",
    "    for call in tool_calls:\n",
    "        tool_name = call[\"function\"][\"name\"]\n",
    "        args = json.loads(call[\"function\"][\"arguments\"])\n",
    "\n",
    "        if tool_name == \"csv_loader\":\n",
    "            result = csv_loader.invoke(args)\n",
    "\n",
    "        elif tool_name == \"plotter\":\n",
    "            result = plotter.invoke(args)\n",
    "\n",
    "        elif tool_name.lower() in [\"python_repl\"]:\n",
    "            result = python_tool.run(args[\"__arg1\"])\n",
    "\n",
    "        messages.append(AIMessage(content=\"\", additional_kwargs={\"tool_calls\": [call]}))\n",
    "        messages.append(ToolMessage(content=result, tool_call_id=call[\"id\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
